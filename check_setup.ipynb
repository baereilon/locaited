{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LocAIted Project Setup Verification\n",
    "\n",
    "This notebook helps you explore and verify the project setup for LocAIted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup imports\nimport sys\nimport os\nfrom pathlib import Path\nfrom datetime import datetime\nimport pandas as pd\nimport json\n\n# Add src to path\nsys.path.insert(0, str(Path.cwd() / \"src\"))\n\n# Import config variables explicitly\nfrom config import (\n    TAVILY_API_KEY, \n    OPENAI_API_KEY, \n    DATABASE_URL, \n    MAX_COST_PER_QUERY, \n    OPENAI_MODEL,\n    PROJECT_ROOT, \n    TEST_DATA_PATH, \n    DEFAULT_CITY, \n    DEFAULT_DATE_RANGE_DAYS,\n    TAVILY_SEARCH_DEPTH, \n    TAVILY_MAX_RESULTS, \n    TAVILY_EXTRACT_MAX_URLS\n)\n\n# Import database components explicitly\nfrom database import (\n    Base, \n    User, \n    Event, \n    Recommendation, \n    Feedback, \n    QueryCache,\n    init_db, \n    get_db, \n    create_user, \n    get_or_create_event, \n    create_recommendation,\n    add_feedback, \n    check_cache, \n    save_to_cache\n)\n\nprint(\"✅ Imports successful!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.13.3 (v3.13.3:6280bb54784, Apr  8 2025, 10:47:54) [Clang 15.0.0 (clang-1500.3.9.4)]\n",
      "\n",
      "Virtual Environment: /Users/eilonbaer/Projects/locaited/venv\n",
      "\n",
      "Project Root: /Users/eilonbaer/Projects/locaited\n",
      "Test Data Path: /Users/eilonbaer/Projects/locaited/test data/Liri Interesting events.csv\n",
      "Database: sqlite:///locaited.db\n"
     ]
    }
   ],
   "source": [
    "# Check Python version and environment\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"\\nVirtual Environment: {sys.prefix}\")\n",
    "print(f\"\\nProject Root: {PROJECT_ROOT}\")\n",
    "print(f\"Test Data Path: {TEST_DATA_PATH}\")\n",
    "print(f\"Database: {DATABASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. API Keys Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Keys Status:\n",
      "\n",
      "✅ Tavily API Key: tvly-dev-e...TDyw\n",
      "✅ OpenAI API Key: sk-svcacct...kYIA\n",
      "\n",
      "OpenAI Model: gpt-3.5-turbo\n",
      "Max Cost per Query: $0.1\n",
      "\n",
      "Tavily Settings:\n",
      "  - Search Depth: basic\n",
      "  - Max Results: 15\n",
      "  - Max URLs to Extract: 8\n"
     ]
    }
   ],
   "source": [
    "# Check API keys (masked for security)\n",
    "def mask_key(key):\n",
    "    if key:\n",
    "        return key[:10] + \"...\" + key[-4:]\n",
    "    return \"NOT CONFIGURED\"\n",
    "\n",
    "print(\"API Keys Status:\")\n",
    "print(f\"\\n✅ Tavily API Key: {mask_key(TAVILY_API_KEY)}\")\n",
    "print(f\"✅ OpenAI API Key: {mask_key(OPENAI_API_KEY)}\")\n",
    "print(f\"\\nOpenAI Model: {OPENAI_MODEL}\")\n",
    "print(f\"Max Cost per Query: ${MAX_COST_PER_QUERY}\")\n",
    "print(f\"\\nTavily Settings:\")\n",
    "print(f\"  - Search Depth: {TAVILY_SEARCH_DEPTH}\")\n",
    "print(f\"  - Max Results: {TAVILY_MAX_RESULTS}\")\n",
    "print(f\"  - Max URLs to Extract: {TAVILY_EXTRACT_MAX_URLS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dependencies Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed Packages:\n",
      "✅ Agent Orchestration  (langgraph): installed\n",
      "✅ Web Search API       (tavily): installed\n",
      "✅ LLM API              (openai): 1.99.9\n",
      "✅ Database ORM         (sqlalchemy): 2.0.43\n",
      "✅ API Framework        (fastapi): 0.116.1\n",
      "✅ Data Validation      (pydantic): 2.11.7\n"
     ]
    }
   ],
   "source": [
    "# Check installed packages\n",
    "packages = [\n",
    "    ('langgraph', 'Agent Orchestration'),\n",
    "    ('tavily', 'Web Search API'),\n",
    "    ('openai', 'LLM API'),\n",
    "    ('sqlalchemy', 'Database ORM'),\n",
    "    ('fastapi', 'API Framework'),\n",
    "    ('pydantic', 'Data Validation')\n",
    "]\n",
    "\n",
    "print(\"Installed Packages:\")\n",
    "for package, description in packages:\n",
    "    try:\n",
    "        module = __import__(package.replace('-', '_'))\n",
    "        version = getattr(module, '__version__', 'installed')\n",
    "        print(f\"✅ {description:20} ({package}): {version}\")\n",
    "    except ImportError:\n",
    "        print(f\"❌ {description:20} ({package}): Not installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Database Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database initialized at sqlite:///locaited.db\n",
      "Database Tables:\n",
      "  • users\n",
      "  • events\n",
      "  • recommendations\n",
      "  • feedback\n",
      "  • query_cache\n"
     ]
    }
   ],
   "source": [
    "# Initialize database if needed\n",
    "init_db()\n",
    "\n",
    "# Show tables\n",
    "print(\"Database Tables:\")\n",
    "for table_name in Base.metadata.tables.keys():\n",
    "    print(f\"  • {table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Record Counts:\n",
      "  Users          : 2\n",
      "  Events         : 2\n",
      "  Recommendations: 1\n",
      "  Feedback       : 0\n",
      "  Cached Queries : 0\n"
     ]
    }
   ],
   "source": [
    "# Check database contents\n",
    "db = next(get_db())\n",
    "\n",
    "stats = {\n",
    "    'Users': db.query(User).count(),\n",
    "    'Events': db.query(Event).count(),\n",
    "    'Recommendations': db.query(Recommendation).count(),\n",
    "    'Feedback': db.query(Feedback).count(),\n",
    "    'Cached Queries': db.query(QueryCache).count()\n",
    "}\n",
    "\n",
    "print(\"Database Record Counts:\")\n",
    "for table, count in stats.items():\n",
    "    print(f\"  {table:15}: {count}\")\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Events in Database:\n",
      "  • Test Event\n",
      "    Location: NYC\n",
      "    Organizer: Test Org\n",
      "    Created: 2025-08-18 12:13:30.277938\n",
      "\n",
      "  • Test Notebook Event\n",
      "    Location: NYC\n",
      "    Organizer: Notebook Org\n",
      "    Created: 2025-08-18 13:26:06.168377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show sample data if exists\n",
    "db = next(get_db())\n",
    "\n",
    "if db.query(Event).count() > 0:\n",
    "    print(\"Sample Events in Database:\")\n",
    "    events = db.query(Event).limit(5).all()\n",
    "    for event in events:\n",
    "        print(f\"  • {event.title}\")\n",
    "        print(f\"    Location: {event.location}\")\n",
    "        print(f\"    Organizer: {event.organizer}\")\n",
    "        print(f\"    Created: {event.created_at}\\n\")\n",
    "else:\n",
    "    print(\"No events in database yet.\")\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data: 20 events loaded\n",
      "\n",
      "Columns: ['Day', 'date', 'event', 'type', 'access', 'Location ', 'Time']\n",
      "\n",
      "First 5 events:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>date</th>\n",
       "      <th>event</th>\n",
       "      <th>type</th>\n",
       "      <th>access</th>\n",
       "      <th>Location</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Mar 14, 2025</td>\n",
       "      <td>Purim</td>\n",
       "      <td>Cultural Event</td>\n",
       "      <td>open to all</td>\n",
       "      <td>South Williamsburg</td>\n",
       "      <td>Throughout the day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Mar 17, 2025</td>\n",
       "      <td>St. Patrick's Day Parade</td>\n",
       "      <td>Parade</td>\n",
       "      <td>open to all</td>\n",
       "      <td>Marches along Fifth Avenue from 44th to 79th S...</td>\n",
       "      <td>Starts at 11:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Mar 19, 2025</td>\n",
       "      <td>Eli Sharabi in the UN</td>\n",
       "      <td>Political event</td>\n",
       "      <td>Need to be approved</td>\n",
       "      <td>United Nations HQ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Apr 1, 2025</td>\n",
       "      <td>International women of courge</td>\n",
       "      <td>Political event</td>\n",
       "      <td>Need to be approved</td>\n",
       "      <td>Department of State, DC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>Apr 5, 2025</td>\n",
       "      <td>Hands off (Protest against trump)</td>\n",
       "      <td>Protest</td>\n",
       "      <td>Press Card only</td>\n",
       "      <td>Bryant Park</td>\n",
       "      <td>1:00 PM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Day          date                              event  \\\n",
       "0        NaN  Mar 14, 2025                             Purim    \n",
       "1    Monday   Mar 17, 2025           St. Patrick's Day Parade   \n",
       "2  Wednesday  Mar 19, 2025             Eli Sharabi in the UN    \n",
       "3    Tuesday   Apr 1, 2025      International women of courge   \n",
       "4   Saturday   Apr 5, 2025  Hands off (Protest against trump)   \n",
       "\n",
       "              type               access  \\\n",
       "0   Cultural Event          open to all   \n",
       "1           Parade          open to all   \n",
       "2  Political event  Need to be approved   \n",
       "3  Political event  Need to be approved   \n",
       "4          Protest     Press Card only    \n",
       "\n",
       "                                           Location                 Time  \n",
       "0                                 South Williamsburg  Throughout the day  \n",
       "1  Marches along Fifth Avenue from 44th to 79th S...  Starts at 11:00 AM  \n",
       "2                                  United Nations HQ                 NaN  \n",
       "3                            Department of State, DC                 NaN  \n",
       "4                                        Bryant Park             1:00 PM  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and explore test data\n",
    "if TEST_DATA_PATH.exists():\n",
    "    df = pd.read_csv(TEST_DATA_PATH)\n",
    "    print(f\"Test Data: {len(df)} events loaded\")\n",
    "    print(f\"\\nColumns: {list(df.columns)}\")\n",
    "    print(f\"\\nFirst 5 events:\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(f\"Test data file not found at: {TEST_DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event Types Distribution:\n",
      "  Cultural Event      : 7 events\n",
      "  Political event     : 5 events\n",
      "  News                : 4 events\n",
      "  Parade              : 2 events\n",
      "  Protest             : 2 events\n",
      "\n",
      "Access Requirements:\n",
      "  Need to be approved : 7 events\n",
      "  open to all         : 6 events\n",
      "  Press Card only     : 6 events\n"
     ]
    }
   ],
   "source": [
    "# Analyze event types\n",
    "if 'df' in locals():\n",
    "    print(\"Event Types Distribution:\")\n",
    "    type_counts = df['type'].value_counts()\n",
    "    for event_type, count in type_counts.items():\n",
    "        print(f\"  {event_type:20}: {count} events\")\n",
    "    \n",
    "    print(f\"\\nAccess Requirements:\")\n",
    "    access_counts = df['access'].value_counts()\n",
    "    for access_type, count in access_counts.items():\n",
    "        print(f\"  {access_type:20}: {count} events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Events for Testing:\n",
      "\n",
      "Protests:\n",
      "  • Hands off (Protest against trump) - Apr 5, 2025\n",
      "  • March to Protect Migrants and the Planet By 50501 NY - Apr 19, 2025\n",
      "\n",
      "Cultural Events:\n",
      "  • Purim  - Mar 14, 2025\n",
      "  • Easter Parade - Apr 20, 2025\n",
      "\n",
      "Political Events:\n",
      "  • Eli Sharabi in the UN  - Mar 19, 2025\n",
      "  • International women of courge - Apr 1, 2025\n"
     ]
    }
   ],
   "source": [
    "# Show interesting events for testing\n",
    "if 'df' in locals():\n",
    "    print(\"Sample Events for Testing:\")\n",
    "    print(\"\\nProtests:\")\n",
    "    protests = df[df['type'] == 'Protest'].head(2)\n",
    "    for _, row in protests.iterrows():\n",
    "        print(f\"  • {row['event']} - {row['date']}\")\n",
    "    \n",
    "    print(\"\\nCultural Events:\")\n",
    "    cultural = df[df['type'] == 'Cultural Event'].head(2)\n",
    "    for _, row in cultural.iterrows():\n",
    "        print(f\"  • {row['event']} - {row['date']}\")\n",
    "    \n",
    "    print(\"\\nPolitical Events:\")\n",
    "    political = df[df['type'] == 'Political event'].head(2)\n",
    "    for _, row in political.iterrows():\n",
    "        print(f\"  • {row['event']} - {row['date']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Structure:\n",
      "├── .DS_Store\n",
      "├── .env\n",
      "├── .gitignore\n",
      "├── .ipynb_checkpoints\n",
      "│   └── check_setup-checkpoint.ipynb\n",
      "├── check_setup.ipynb\n",
      "├── data\n",
      "├── documents\n",
      "│   └── Agent Architecture (Cyclic LangGraph, cost-aware Tavily use).pdf\n",
      "├── environment.yml\n",
      "├── locaited.db\n",
      "├── main.py\n",
      "├── requirements.txt\n",
      "├── setup.sh\n",
      "├── setup_venv.sh\n",
      "├── src\n",
      "│   ├── __init__.py\n",
      "│   ├── agents\n",
      "│   │   ├── __init__.py\n",
      "│   │   └── workflow.py\n",
      "│   ├── config.py\n",
      "│   ├── database.py\n",
      "│   └── utils\n",
      "│       └── __init__.py\n",
      "├── test data\n",
      "│   └── Liri Interesting events.csv\n"
     ]
    }
   ],
   "source": [
    "# Show project structure\n",
    "import os\n",
    "\n",
    "def show_tree(path, prefix=\"\", max_depth=3, current_depth=0):\n",
    "    if current_depth >= max_depth:\n",
    "        return\n",
    "    \n",
    "    items = sorted(Path(path).iterdir())\n",
    "    for i, item in enumerate(items):\n",
    "        # Skip certain directories\n",
    "        if item.name in ['venv', '__pycache__', '.git', '.vscode', 'micromamba']:\n",
    "            continue\n",
    "        \n",
    "        is_last = i == len(items) - 1\n",
    "        current_prefix = \"└── \" if is_last else \"├── \"\n",
    "        print(f\"{prefix}{current_prefix}{item.name}\")\n",
    "        \n",
    "        if item.is_dir():\n",
    "            next_prefix = prefix + (\"    \" if is_last else \"│   \")\n",
    "            show_tree(item, next_prefix, max_depth, current_depth + 1)\n",
    "\n",
    "print(\"Project Structure:\")\n",
    "show_tree(\".\", max_depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Database Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test user exists: Notebook Test User\n",
      "   ID: 2\n",
      "   Email: notebook@test.com\n",
      "   Location: NYC\n",
      "   Interests: ['protests', 'cultural', 'political']\n"
     ]
    }
   ],
   "source": [
    "# Test creating a user\n",
    "db = next(get_db())\n",
    "\n",
    "# Check if test user exists\n",
    "test_user = db.query(User).filter_by(email=\"notebook@test.com\").first()\n",
    "\n",
    "if not test_user:\n",
    "    test_user = create_user(\n",
    "        db,\n",
    "        name=\"Notebook Test User\",\n",
    "        email=\"notebook@test.com\",\n",
    "        primary_location=\"NYC\",\n",
    "        interest_areas=[\"protests\", \"cultural\", \"political\"]\n",
    "    )\n",
    "    print(f\"✅ Created test user: {test_user.name}\")\n",
    "else:\n",
    "    print(f\"✅ Test user exists: {test_user.name}\")\n",
    "\n",
    "print(f\"   ID: {test_user.id}\")\n",
    "print(f\"   Email: {test_user.email}\")\n",
    "print(f\"   Location: {test_user.primary_location}\")\n",
    "print(f\"   Interests: {test_user.interest_areas}\")\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First call - Event ID: 3\n",
      "Second call - Event ID: 3\n",
      "✅ Deduplication working correctly!\n"
     ]
    }
   ],
   "source": [
    "# Test event deduplication\n",
    "db = next(get_db())\n",
    "\n",
    "event_data = {\n",
    "    'title': \"Test Notebook Event\",\n",
    "    'start_time': datetime.now(),\n",
    "    'location': \"NYC\",\n",
    "    'organizer': \"Notebook Org\",\n",
    "    'summary': \"Test event from notebook\"\n",
    "}\n",
    "\n",
    "# Create event twice - should deduplicate\n",
    "event1 = get_or_create_event(db, event_data)\n",
    "print(f\"First call - Event ID: {event1.id}\")\n",
    "\n",
    "event2 = get_or_create_event(db, event_data)\n",
    "print(f\"Second call - Event ID: {event2.id}\")\n",
    "\n",
    "if event1.id == event2.id:\n",
    "    print(\"✅ Deduplication working correctly!\")\n",
    "else:\n",
    "    print(\"❌ Deduplication not working\")\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Quick API Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tavily client initialized successfully\n",
      "   Ready to search with depth='basic'\n",
      "   Max results: 15\n"
     ]
    }
   ],
   "source": [
    "# Test Tavily connection (without making actual API call)\n",
    "from tavily import TavilyClient\n",
    "\n",
    "try:\n",
    "    client = TavilyClient(api_key=TAVILY_API_KEY)\n",
    "    print(\"✅ Tavily client initialized successfully\")\n",
    "    print(f\"   Ready to search with depth='{TAVILY_SEARCH_DEPTH}'\")\n",
    "    print(f\"   Max results: {TAVILY_MAX_RESULTS}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Tavily initialization error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OpenAI client initialized successfully\n",
      "   Model: gpt-3.5-turbo\n",
      "   Budget: $0.1 per query\n"
     ]
    }
   ],
   "source": [
    "# Test OpenAI connection (without making actual API call)\n",
    "from openai import OpenAI\n",
    "\n",
    "try:\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    print(\"✅ OpenAI client initialized successfully\")\n",
    "    print(f\"   Model: {OPENAI_MODEL}\")\n",
    "    print(f\"   Budget: ${MAX_COST_PER_QUERY} per query\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ OpenAI initialization error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. LangGraph Workflow Testing (NEW!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 2 Progress:\n",
      "\n",
      "✅ LangGraph Skeleton - COMPLETE!\n",
      "\n",
      "⏳ Profile & Planner Agent - Parse CSV and build real profile\n",
      "⏳ Retriever Agent - Integrate Tavily search API\n",
      "⏳ Extractor Agent - Extract event details from URLs\n",
      "⏳ Recommender Agent - Score and rank events\n",
      "\n",
      "📍 Current: The workflow skeleton is working with mock data.\n",
      "📍 Next: Build Profile & Planner to parse the test CSV.\n"
     ]
    }
   ],
   "source": [
    "# Phase 2 Progress Update\n",
    "completed = [\"✅ LangGraph Skeleton - COMPLETE!\"]\n",
    "pending = [\n",
    "    \"⏳ Profile & Planner Agent - Parse CSV and build real profile\",\n",
    "    \"⏳ Retriever Agent - Integrate Tavily search API\",\n",
    "    \"⏳ Extractor Agent - Extract event details from URLs\",\n",
    "    \"⏳ Recommender Agent - Score and rank events\"\n",
    "]\n",
    "\n",
    "print(\"Phase 2 Progress:\\n\")\n",
    "for item in completed:\n",
    "    print(item)\n",
    "print()\n",
    "for item in pending:\n",
    "    print(item)\n",
    "\n",
    "print(\"\\n📍 Current: The workflow skeleton is working with mock data.\")\n",
    "print(\"📍 Next: Build Profile & Planner to parse the test CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Next Steps - Phase 2 (Updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User Profile Built:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# View the user profile that was built\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mUser Profile Built:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m profile = \u001b[43mresult\u001b[49m[\u001b[33m'\u001b[39m\u001b[33muser_profile\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Domains: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprofile[\u001b[33m'\u001b[39m\u001b[33mallowlist_domains\u001b[39m\u001b[33m'\u001b[39m][:\u001b[32m3\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# First 3 domains\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Keywords: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprofile[\u001b[33m'\u001b[39m\u001b[33mkeywords\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "# View the user profile that was built\n",
    "print(\"\\nUser Profile Built:\")\n",
    "profile = result['user_profile']\n",
    "print(f\"  Domains: {profile['allowlist_domains'][:3]}...\")  # First 3 domains\n",
    "print(f\"  Keywords: {profile['keywords']}\")\n",
    "print(f\"  Interest Areas: {profile['interest_areas']}\")\n",
    "print(f\"  Credentials: {profile['credentials']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the state structure\n",
    "print(\"\\nWorkflow State Keys:\")\n",
    "for key in result.keys():\n",
    "    value = result[key]\n",
    "    if isinstance(value, list):\n",
    "        print(f\"  • {key}: {len(value)} items\")\n",
    "    elif isinstance(value, dict):\n",
    "        print(f\"  • {key}: {type(value).__name__} with {len(value)} keys\")\n",
    "    else:\n",
    "        print(f\"  • {key}: {type(value).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the workflow logs to understand the flow\n",
    "print(\"\\nWorkflow Execution Logs:\")\n",
    "for log in result['logs'][-10:]:  # Last 10 logs\n",
    "    print(f\"  • {log}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the recommendations\n",
    "print(\"\\nTop Recommendations:\")\n",
    "for i, event in enumerate(result['top10'], 1):\n",
    "    print(f\"\\n{i}. {event['title']}\")\n",
    "    print(f\"   Score: {event['recommendation']:.2f}\")\n",
    "    print(f\"   Location: {event['location']}\")\n",
    "    print(f\"   Rationale: {event['rationale'][:100]}...\")  # First 100 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the workflow with a simple query\n",
    "result = run_workflow(\n",
    "    query=\"Find protests and cultural events in NYC\",\n",
    "    city=\"NYC\",\n",
    "    days_ahead=14\n",
    ")\n",
    "\n",
    "print(f\"Query: {result['query_spec']['text']}\")\n",
    "print(f\"Cycles executed: {result['cycle_count']}\")\n",
    "print(f\"Total cost: ${result['total_cost']:.4f}\")\n",
    "print(f\"Events found: {len(result['top10'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the new workflow module\n",
    "from agents.workflow import *\n",
    "\n",
    "print(\"✅ LangGraph workflow module imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "  LocAIted Setup Summary\n",
      "============================================================\n",
      "✅ Environment configured\n",
      "✅ API keys configured\n",
      "✅ Database initialized\n",
      "✅ Test data available\n",
      "✅ Dependencies installed\n",
      "\n",
      "🎉 Phase 1 Complete! Ready for Phase 2: Building Agents\n"
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "print(\"=\"*60)\n",
    "print(\"  LocAIted Setup Summary\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "checklist = [\n",
    "    (\"Environment configured\", 'venv' in sys.prefix or 'micromamba' in sys.prefix),\n",
    "    (\"API keys configured\", bool(TAVILY_API_KEY and OPENAI_API_KEY)),\n",
    "    (\"Database initialized\", Path(DATABASE_URL.replace('sqlite:///', '')).exists()),\n",
    "    (\"Test data available\", TEST_DATA_PATH.exists()),\n",
    "    (\"Dependencies installed\", True)  # If we got this far, they're installed\n",
    "]\n",
    "\n",
    "all_good = True\n",
    "for task, status in checklist:\n",
    "    icon = \"✅\" if status else \"❌\"\n",
    "    print(f\"{icon} {task}\")\n",
    "    all_good = all_good and status\n",
    "\n",
    "if all_good:\n",
    "    print(\"\\n🎉 Phase 1 Complete! Ready for Phase 2: Building Agents\")\n",
    "else:\n",
    "    print(\"\\n⚠️  Some items need attention before proceeding to Phase 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}